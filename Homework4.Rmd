---
title: "Homework 4"
author: "Ivan Ao"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(wordcloud)
```

# Instructions
- If you wish to use any additional packages beyond "Base R" or `wordcloud`then email Rebecca (`rkurt001@ucr.edu`) for permission. 
- Use R to answer the questions below. 
- Check Piazza regularly for clarification on questions, there may be important posts that will not be announced through *Elearn*.  


# Questions 

Use the `Starbucks.csv` data set on ELearn. This data set comes from [Kaggle.com](https://www.kaggle.com/starbucks/store-locations) and contains general information about all the Starbucks locations worldwide as of February 2017.
```{r}
starbucks <- read.csv("./Starbucks.csv")
```

# PART 1

**Question 1:Starbucks Data (11 points)**

1a) (1 point) Create a subset of all the Starbucks locations in California. HINT: Check the columns `Brand`, `State.Province`, AND `Country`.  How many rows are in this data set? Display the first 15 lines. 
```{r}
ca <- starbucks[which(starbucks$State.Province == "CA"),]
location <- ca$Street.Address
location[1:15]
```


1b) (2 points) The postal codes in the Starbucks data set are also not standardized, even when we only consider the Starbucks stores in California.  Postal codes are generally are five digits, or they are five digits with a dash and four additional digits.  For example: 12345, 12345-6789.  Standardize the postal code column for the California Starbucks' data set. If there is no postal code replace it with `NA`. Display the first 100 values of this corrected column. 
```{r}
postalCodes <- replace(ca$Postcode, ca$Postcode == "", NA)
temp <- postalCodes[nchar(postalCodes) > 5]
postalCodes[nchar(postalCodes) > 5] <- paste(substr(temp,1,5), "-", substr(temp,6,9))
postalCodes <- gsub(" ", "", postalCodes)
postalCodes[1:100]
```



1c) (2 points) The phone numbers in the Starbucks data set are not standardized, even when we only consider the Starbucks stores in California.  Phone numbers typically have ten digits.  Standardize the phone number column for the California Starbucks' data set so the structure is the same for the whole column.  Phone numbers should be in the following form: (123) 456-7890. If there is no phone number replace it with NA. Display the first 100 values of this corrected column. HINT: Remember the symbols: . \ | ( ) [ { ^ $ * + ? all have special meanings in text analysis. They are apart of the "regular expressions" syntax, and we need to use an escape key if we want to remove the special meaning.
```{r}
phoneNumbers <- gsub(" ", "",gsub("[[:punct:]]", "", ca$Phone.Number))
phoneNumbers <- paste("(",substr(phoneNumbers,1,3), ")", substr(phoneNumbers,4,6), "-", substr(phoneNumbers,7,10))
phoneNumbers <- gsub(" ", "", phoneNumbers)
phoneNumbers <- replace(phoneNumbers, phoneNumbers == "()-", NA)

phoneNumbers[1:100]
```


1d) (1 point) Find the number of locations in California that are in a city that starts with the letter "R".
```{r}
length(ca$City[grep("R", substr(ca$City,1,1))])
```

1e) (1 point) Create a frequency table for the cities that contain Starbucks' in California.  Display only the 25 cities that have the most amount of Starbucks'. 
```{r}
fre_tab <- sort(table(ca$City), decreasing = T)
fre_tab[1:15]
```



1f) (1 point) Create a word cloud for the Starbucks' in California.  Have the words be the city names, and let the size of the words be proportional to the amount of Starbucks in that city. NOTE: You do not need to include all the cities, just do a subset. 
```{r}
wordcloud(words = names(fre_tab[1:15]), freq = fre_tab[1:15])
```


1f) (3 points) Notice that the Starbucks data set has a `Timezone` column.  This column is contains the timezone and lists the continent/ocean-region/etc the Starbucks is located at, followed by a slash and then a major city within the timezone. Create a new factor column and add it to the data set. The new column should be called `Timezone_Continent`, and should contain only the continent/ocean-region/etc information the Starbucks is on. For example, if `Timezone = "GMT+1:00 Europe/Andorra"`, then `Timezone_Continent = "Europe"`. Display the first few lines of the full data set with this new variable. 
```{r}
temp <- sapply(strsplit(sapply(strsplit(starbucks$Timezone, " "),"[[",2), "\\/"), "[[", 2)
starbucks <- data.frame(starbucks, Timezone_Continent = temp)
starbucks$Timezone_Continent[1:10]

```


**Question 2: Some practice with *apply functions (7 points) **


2a) (1 point) Using `sapply()`, determine the class of each column. 
```{r}
sapply(starbucks, class)
```


2b) (2 points) Create a frequency table for the number of Starbucks locations in California that start with the letter "A", "B", ..., "Z".
```{r}
sort(table(substr(ca$City, 1, 1)), decreasing = T)
```

2c) (3 points) Create a data frame with three columns.  Let one column be a state in the USA, the second column be the city within that state that has the most Starbucks locations, and let the third column be the number of locations within that city.  
```{r}
most_starbucks <- function(x)
{
  return(names(which.max(table(starbucks$City[starbucks$State.Province == x]))))
}
number_of_locations <- function(x)
{
  return(nrow(subset(starbucks, City == x))) 
}
state <- unique(starbucks$State.Province[starbucks$Country == "US"])
city <- sapply(state,most_starbucks)
numbers <- sapply(city,number_of_locations)
new_df <- data.frame(state,city,numbers)
new_df
```

2d) (1 point) Create a word cloud that corresponds to the data set in Q2c. Have the words be the city names, and let the size of the words be proportional to the amount of Starbucks in that city. NOTE: You do not need to include all the cities, just do a subset. 
```{r}
ftable <- c(new_df$numbers)
names(ftable) <- c(new_df$city)
wordcloud(words = names(ftable[1:30]), freq = ftable[1:30])

```


# PART 2

**Question 3: Help Files (12 points) **

Create your own version of a help file for the function in the "Hwk4FuncForTemplate.R" document using the "Hwk4FunctionTemplate.RMD" file. 

Look at other help files in R to help you write yours. For example: ifelse, median, sd, sum, sqrt, etc.
